{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylan/snap/jupyter/common/lib/python3.7/site-packages/joblib/_multiprocessing_helpers.py:45: UserWarning: [Errno 13] Permission denied.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    }
   ],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "#import ssl\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "#import the necessary modelling algos.\n",
    "\n",
    "#classifiaction.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#regression\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#model selection\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#evaluation metrics\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error # for regression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  # for classification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, tree, preprocessing, metrics, linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "import datetime\n",
    "import catboost\n",
    "from catboost import CatBoostRegressor, Pool, cv\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import model_selection, tree, preprocessing, metrics, linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xg\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pdr.get_data_yahoo('AVOD.IS', start=\"2017-01-01\", end=\"2040-04-30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>1.29</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2953885.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>1.27</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2567470.0</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>1.22</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2951122.0</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>1.21</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3236080.0</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>1.22</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1819167.0</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            High   Low  Open  Close     Volume  Adj Close\n",
       "Date                                                     \n",
       "2017-01-02  1.29  1.22  1.23   1.25  2953885.0       1.25\n",
       "2017-01-03  1.27  1.20  1.26   1.22  2567470.0       1.22\n",
       "2017-01-04  1.22  1.16  1.20   1.18  2951122.0       1.18\n",
       "2017-01-05  1.21  1.17  1.19   1.18  3236080.0       1.18\n",
       "2017-01-06  1.22  1.18  1.19   1.20  1819167.0       1.20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=['AVOD ', 'A1CAP, ACP ', 'ACSEL ', 'ADEL ', 'ADESE ', 'AFYON ',\n",
    "       'AGHOL ', 'AKSFA ', 'AKM, AKMEN ', 'AKBNK ', 'AKCNS ', 'AKDFA ',\n",
    "       'AKYHO ', 'AKENR ', 'AKFGY ', 'AKFEN ', 'ATEKS ', 'AKSGY ',\n",
    "       'AKMGY ', 'AKSA ', 'AKSEN ', 'AKGRT ', 'AKSUE ', 'AKTVK ',\n",
    "       'AFB, AKTIF ', 'ALCAR ', 'ALGYO ', 'ALARK ', 'ALBRK, ALK ',\n",
    "       'ALCTL ', 'ALKIM ', 'ALKA ', 'ALNTF, ANF ', 'AYCES ', 'ALMAD ',\n",
    "       'ANSGR ', 'AEFES ', 'ANHYT ', 'ASUZU ', 'ANELE ', 'ARCLK ',\n",
    "       'ARDYZ ', 'ARENA ', 'ARNFK ', 'ARMDA ', 'ARSAN ', 'ARTI ',\n",
    "       'ASELS ', 'ATAGY ', 'AGYO ', 'ATLFA ', 'ATSYH ', 'ATLAS ',\n",
    "       'AVISA ', 'AVGYO ', 'AVTUR ', 'AVHOL ', 'AYEN ', 'AYES ', 'AYGAZ ',\n",
    "       'B', 'BAGFS ', 'BAKAB ', 'BALAT ', 'BNTAS ', 'BANVT ', 'BSRFK ',\n",
    "       'BASCM ', 'BTCIM ', 'BSOKE ', 'BAYRK ', 'BERA ', 'BRKT ', 'BRKSN ',\n",
    "       'BJKAS ', 'BEYAZ ', 'BLCYT ', 'BIMAS ', 'BRKVY ', 'BRKO ',\n",
    "       'BRMEN ', 'BIZIM ', 'BOGVY ', 'BRSAN ', 'BRYAT ', 'BFREN ',\n",
    "       'BOSSA ', 'BRISA ', 'BURCE ', 'BURVA ', 'BUCIM ', 'C', 'CRFSA ',\n",
    "       'CASA ', 'CEOEM ', 'CCOLA ', 'COSMO ', 'CRDFA ', 'Ã‡', 'CLEBI ',\n",
    "       'CELHA ', 'CEMAS ', 'CEMTS ', 'CMBTN ', 'CMENT ', 'CIMSA ',\n",
    "       'CUSAN ', 'D', 'DAGI ', 'DAGHL ', 'DARDL ', 'DGATE ', 'DMSAS ',\n",
    "       'DENVA ', 'DENGE ', 'DENFA ', 'DNFIN ', 'DZGYO ', 'DZY, DZYMK ',\n",
    "       'DENIZ, DNZ ', 'DERIM ', 'DERAS ', 'DESA ', 'DESPC ', 'DSTKF ',\n",
    "       'DEVA ', 'DEVIR ', 'DNISI ', 'DIRIT ', 'DITAS ', 'DOCO ', 'DOBUR ',\n",
    "       'DOHOL ', 'DGKLB ', 'DOGUB ', 'DGGYO ', 'DGHOL ', 'DOAS ',\n",
    "       'DFKTR ', 'DOKTA ', 'DURDO ', 'DNYVA ', 'DYOBY ', 'E', 'ECZYT ',\n",
    "       'EDIP ', 'EGEEN ', 'EGGUB ', 'EGPRO ', 'EGSER ', 'EPLAS ',\n",
    "       'ECILC ', 'EKIZ ', 'EKOFA ', 'EMKEL ', 'EMNIS ', 'EKTVK ',\n",
    "       'EKGYO ', 'ENJSA ', 'ENKAI ', 'ERBOS ', 'EREGL ', 'ERGLI ',\n",
    "       'EROGL ', 'ERSU ', 'ESCOM ', 'ESEN ', 'ETILR ', 'EUKYO ', 'EUYO ',\n",
    "       'ETYAT ', 'EUHOL ', 'F', 'FADE ', 'FMIZP ', 'FENER ',\n",
    "       'FBB, FBBNK ', 'FLAP ', 'FONET ', 'FROTO ', 'FORMT ', 'FRIGO ',\n",
    "       'G', 'GSRAY ', 'GARFA ', 'GRFIN ', 'GRNYO ', 'GEDIK ', 'GEDZA ',\n",
    "       'GENTS ', 'GEREL ', 'GLB, GLBMD ', 'GLYHO ', 'GOODY ', 'GOLTS ',\n",
    "       'GOZDE ', 'GSDDE ', 'GSDHO ', 'GUBRF ', 'GLRYH ', 'H', 'SAHOL ',\n",
    "       'HALKF ', 'HLGYO ', 'HLVKS ', 'HATEK ', 'HDFGS ', 'HEKTS ',\n",
    "       'HSB, HSBCB ', 'HUBVC ', 'HUZFA ', 'HURGZ ', 'I', 'ICB, ICBCT ',\n",
    "       'INVEO ', 'IEYHO ', 'Ä°', 'IDEAS ', 'IDGYO ', 'IHEVA ', 'IHLGM ',\n",
    "       'IHGZT ', 'IHLAS ', 'IHYAY ', 'INDES ', 'INFO, IYF ', 'INTEM ',\n",
    "       'IPEKE ', 'ISDMR ', 'ISFAK ', 'ISFIN ', 'ISGYO ', 'ISGSY ',\n",
    "       'ISMEN, IYM ', 'ISYAT ', 'ISBIR ', 'ITTFH ', 'IZTAR ', 'IZMDC ',\n",
    "       'IZFAS ', 'J', 'JANTS ', 'K', 'KFEIN ', 'KALES ',\n",
    "       'KAPTESTAS001, TRAKAPTEST01 ', 'KAPLM ', 'KRDMA, KRDMB, KRDMD ',\n",
    "       'KAREL ', 'KARSN ', 'KRTEK ', 'KARTN ', 'KATMR ', 'KNTFA ',\n",
    "       'KENT ', 'KERVT ', 'KRVGD ', 'KERVN ', 'KLGYO ', 'KLMSN ',\n",
    "       'KFKTF ', 'KOCFN ', 'KCHOL ', 'KNFRT ', 'KONTR ', 'KONYA ',\n",
    "       'KORDS ', 'KORTS ', 'KOZAL ', 'KOZAA ', 'KRGYO ', 'KRSTL ',\n",
    "       'KRONT ', 'KTKVK ', 'KSTUR ', 'KUYAS ', 'KUTPO ', 'L', 'LIDFA ',\n",
    "       'LINK ', 'LOGO ', 'LKMNH ', 'LUKSK ', 'M', 'MAKTK ', 'MARKA ',\n",
    "       'MAALT ', 'MRSHL ', 'MRGYO ', 'MARTI ', 'MAVI ', 'MZHLD ',\n",
    "       'MEGAP ', 'MNDRS ', 'MEPET ', 'MBFTR ', 'MERIT ', 'MERKO ',\n",
    "       'METUR ', 'METRO ', 'MTRYO ', 'MGROS ', 'MIPAZ ', 'MSGYO ',\n",
    "       'MPARK ', 'MMCAS ', 'TIRE ', 'N', 'NATEN ', 'NTHOL ', 'NETAS ',\n",
    "       'NIBAS ', 'NUHCM ', 'NUGYO ', 'NRHOL ', 'NURVK ', 'NRBNK, NYB ',\n",
    "       'O', 'ODAS ', 'ODB, ODEA ', 'OLMIP ', 'OPET ', 'ORFIN ', 'ORGE ',\n",
    "       'ORMA ', 'OMD, OSMEN ', 'OSTIM ', 'OTKAR ', 'OTOKC ', 'OYAKC ',\n",
    "       'OYA, OYYAT ', 'OYAYO ', 'OYLUM ', 'Ã–', 'OZKGY ', 'OZBAL ',\n",
    "       'OZGYO ', 'OZRDN ', 'P', 'PAMEL ', 'PAGYO ', 'PAPIL ', 'PRKME ',\n",
    "       'PARSN ', 'PBT, PBTR ', 'PGSUS ', 'PEKGY ', 'PENGD ', 'PEGYO ',\n",
    "       'PSDTC ', 'PETKM ', 'PKENT ', 'PHC, PHLLP ', 'PETUN ', 'PINSU ',\n",
    "       'PNSUT ', 'PKART ', 'POLHO ', 'POLTK ', 'PRZMA ', 'Q', 'QNBFF ',\n",
    "       'QNBFL ', 'QNBVK ', 'FNY, QNBFI ', 'FIN, QNBFB ', 'R', 'RALYH ',\n",
    "       'RAYSG ', 'RYGYO ', 'RYSAS ', 'RHEAG ', 'RODRG ', 'ROYAL ',\n",
    "       'RTALB ', 'S', 'SAFKR ', 'SANEL ', 'SANFM ', 'SANKO ', 'SAMAT ',\n",
    "       'SARKY ', 'SARTN ', 'SASA ', 'SAYAS ', 'SEKUR ', 'SELEC ',\n",
    "       'SELGD ', 'SNKRN ', 'SERVE ', 'SRVGY ', 'SEYKM ', 'SILVR ',\n",
    "       'SNGYO ', 'SMART ', 'SODSN ', 'SKTAS ', 'SONME ', 'SNPAM ',\n",
    "       'SUMAS ', 'SMRFA ', 'SMRVA ', 'Åž', 'SEKFA ', 'SEKFK ',\n",
    "       'SKY, SKYMD ', 'SEK, SKBNK ', 'SOKM ', 'T', 'TOKI ', 'TCZ, TCZB ',\n",
    "       'TAC, TCRYT ', 'TACTR ', 'TAMFA ', 'TATGD ', 'TAVHL ', 'TKURU ',\n",
    "       'TEBCE ', 'TEKTU ', 'TKFEN ', 'TKNSA ', 'TMPOL ', 'STK, TRMNK ',\n",
    "       'TFNVK ', 'TGSAS ', 'TOASO ', 'TRGYO ', 'TLMAN ', 'TSPOR ',\n",
    "       'TDGYO ', 'TSGYO ', 'TUCLK ', 'TUKAS ', 'TRCAS ', 'TCELL ',\n",
    "       'TBA, TRKSH ', 'TMSN ', 'TUPRS ', 'TEB, TEBNK ', 'THYAO ',\n",
    "       'PRKAB ', 'TTKOM ', 'TTRAK ', 'TBORG ', 'TURGG ', 'GARAN, TGB ',\n",
    "       'HALKB, THL ', 'EXIMB, THR ', 'ISATR, ISBTR, ISCTR, ISKUR, TIB ',\n",
    "       'KLN, KLNMA ', 'TSK, TSKB ', 'TURSG ', 'SISE ', 'TVB, VAKBN ', 'U',\n",
    "       'UFUK ', 'ULAS ', 'ULSFA ', 'ULUSE ', 'ULUUN ', 'UMPAS ', 'USAK ',\n",
    "       'UTPYA ', 'UZERB ', 'Ãœ', 'ULKER ', 'UNLUS, UNS ', 'V', 'VAKFA ',\n",
    "       'VAKFN ', 'VKGYO ', 'VKFYO ', 'VAKVK ', 'VAKKO ', 'VANGD ',\n",
    "       'VERUS ', 'VERTU ', 'VESBE ', 'VESTL ', 'VKING ', 'Y', 'YKFKT ',\n",
    "       'YKGYO ', 'YKR, YKYAT ', 'YKB, YKBNK ', 'YAPRK ', 'YATAS ',\n",
    "       'YAT, YFMEN ', 'YATVK ', 'YAYLA ', 'YDATH ', 'YGGYO ', 'YGYO ',\n",
    "       'YYAPI ', 'YESIL ', 'YBTAS ', 'YONGA ', 'YKSLN ', 'YUNSA ', 'Z',\n",
    "       'ZKBVK ', 'ZOREN ', 'ZORLF ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AVOD.IS'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tay = pd.Series(l)\n",
    "\n",
    "tay = tay.apply(lambda x: x.split(',')[0])\n",
    "\n",
    "lan = [i for i in l if 7 <=  len(i)]\n",
    "\n",
    "lan = pd.Series(lan).apply(lambda x: x.split(',')[1])\n",
    "\n",
    "type(tay)\n",
    "\n",
    "type(len)\n",
    "\n",
    "lan = np.array(lan)\n",
    "\n",
    "aq = pd.Series(tay.values).append(pd.Series(lan))\n",
    "\n",
    "aq = aq.reset_index()\n",
    "\n",
    "aq = aq.drop(['index'],axis=1)\n",
    "\n",
    "aq[0][0].strip()\n",
    "\n",
    "aq[0][1].strip()\n",
    "\n",
    "aq\n",
    "\n",
    "bq = []\n",
    "for i in range(0,len(aq[0])):\n",
    "  bq.append(aq[0][i].strip())\n",
    "  #bq.append(bq)\n",
    "\n",
    "bq[0]\n",
    "\n",
    "cq = [suit + '.IS' for suit in bq]\n",
    "\n",
    "dq = cq + bq\n",
    "\n",
    "dq = pd.Series(dq)\n",
    "\n",
    "dq = dq.reset_index()\n",
    "\n",
    "dq = dq.drop(['index'],axis=1)\n",
    "\n",
    "dq[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVOD.IS\n",
      "AVOD.IS\n",
      "A1CAP.IS\n",
      "hatalı A1CAP.IS\n",
      "ACSEL.IS\n",
      "ADEL.IS\n",
      "ADESE.IS\n",
      "AFYON.IS\n",
      "CPU times: user 1.14 s, sys: 44 ms, total: 1.18 s\n",
      "Wall time: 6.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hatali = 0\n",
    "print(dq[0][0].strip())\n",
    "data = pdr.get_data_yahoo(dq[0][0].strip(), start=\"2017-01-01\", end=\"2020-04-30\")\n",
    "data = data.rename(columns={\"Adj Close\": dq[0][0].strip()})\n",
    "data = data.reset_index()\n",
    "data = data[['Date',dq[0][0].strip()]]\n",
    "data_merge = data\n",
    "\n",
    "for symbol in range(0,6):\n",
    "    try:\n",
    "        print(dq[0][symbol].strip())\n",
    "        data_new = pdr.get_data_yahoo(dq[0][symbol].strip(), start=\"2015-01-01\", end=\"2022-01-1\")\n",
    "        data_new = data_new.rename(columns={\"Adj Close\": dq[0][symbol].strip()})\n",
    "        data_new = data_new.reset_index()\n",
    "        data_new = data_new[['Date',dq[0][symbol].strip()]]\n",
    "        data_merge = pd.merge(data_merge,data_new,on='Date',how='outer')\n",
    "    except:\n",
    "        print(\"hatalı\",dq[0][symbol].strip())\n",
    "        hatali += 1\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge = data_merge.drop(['AVOD.IS_x'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge = data_merge.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential \n",
    "import lstm, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /home/taylan/snap/jupyter/common/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Collecting pyyaml (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "\u001b[K     |████████████████████████████████| 276kB 2.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /home/taylan/snap/jupyter/common/lib/python3.7/site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/taylan/snap/jupyter/common/lib/python3.7/site-packages (from keras) (1.5.3)\n",
      "Requirement already satisfied: six in /snap/jupyter/6/lib/python3.7/site-packages (from h5py->keras) (1.12.0)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/taylan/snap/jupyter/6/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, keras\n",
      "Successfully installed keras-2.4.3 pyyaml-5.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
